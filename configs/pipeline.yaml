# DeltaV2A Pipeline Configuration (Phase A-C)

device: "mps"

# === Data ===
data:
  # Source (original, non-augmented) data used for training/inference
  audio_dir: "data/original/audio"
  # Optional explicit list (one path per line). If set, this takes precedence over audio_dir.
  audio_list: null
  # Optional split manifest from scripts/build_audio_splits.py (JSONL).
  # If set, this takes precedence over audio_list/audio_dir.
  audio_split_manifest: "data/original/splits/manifest.jsonl"
  audio_split: "train" # one of: train | val | test
  image_dir: "data/original/images"
  max_audio_files: null # null = use all
  max_image_files: null # null = use all
  # Augmented artifacts produced during inverse-mapping DB build
  save_augmented_audio: true
  augmented_audio_dir: "data/augmented/pipeline/audio"

# === Models ===
model:
  clip:
    name: "ViT-L-14"
    pretrained: "openai"
  clap:
    model_id: 1
    enable_fusion: false
    max_duration: 20.0
    sample_rate: 48000

# === Phase A-1: Vocabulary ===
vocab:
  img_terms: null # null = use default IMG_VOCAB_TERMS
  aud_terms: null # null = use default AUD_VOCAB_TERMS

# === Phase A-2: Inverse Mapping Database (Music / Controller) ===
inverse_mapping:
  use_delta_clap: true # true: style label from CLAP(A')-CLAP(A), false: from CLAP(A')
  augmentations_per_audio: 60
  temperature: 0.1
  seed: 42
  min_active_effects: 1
  max_active_effects: 2
  # Minimum intensity for active-effect parameters in normalized [0,1] space.
  # Ensures effects are audibly strong enough to produce meaningful CLAP deltas.
  # - Params with bypass at 0 (e.g. reverb wet_level, delay mix): sampled from [min, 1]
  # - Params with bypass at 1 (e.g. bitcrush bit_depth, lowpass cutoff): sampled from [0, 1-min]
  param_min_intensity: 0.35
  # Weighted effect sampling for active-effect selection in Phase A-3.
  # Higher value -> selected more frequently.
  effect_sampling_weights:
    lowpass: 1.0
    bitcrush: 1.0
    reverb: 1.0
    highpass: 1.0
    distortion: 1.0
    playback_rate: 1.0
    delay: 1.0

# === Phase A-3: Inverse Mapping Database (Image / Siamese) ===
image_inverse_mapping:
  augmentations_per_image: 2
  effect_types:
    [
      "adaptive_blur",
      "motion_blur",
      "adaptive_sharpen",
      "add_noise",
      "spread",
      "sepia_tone",
      "solarize",
    ]
  intensity_min: 0.1
  intensity_max: 1.0
  seed: 42
  save_augmented_images: false
  augmented_image_dir: "data/augmented/pipeline/images"

# === Pedalboard Effects ===
effects:
  active:
    - lowpass
    - bitcrush
    - reverb
    - highpass
    - distortion
    - playback_rate
    - delay

# === Phase B: Controller Training ===
controller:
  # Style-only input: CLAP embedding adds near-zero info (probe shows clap_only â‰ˆ mean baseline).
  # Setting audio_embed_dim=0 removes 512-dim noise and forces the model to rely on
  # the 24-dim delta-CLAP style label which does carry useful signal.
  audio_embed_dim: 0
  hidden_dims: [256, 256, 128]
  dropout: 0.3
  weight_decay: 0.001
  lr_scheduler: "cosine"
  lr_min: 1.0e-6
  use_activity_head: true
  activity_loss_weight: 0.5
  activity_mismatch_weight: 2.0
  activity_mismatch_gamma: 2.0
  activity_loss_type: "asl" # one of: bce, focal, asl
  focal_gamma: 2.0
  asl_gamma_pos: 0.0
  asl_gamma_neg: 4.0
  asl_clip: 0.05
  param_loss_weight: 1.0
  inactive_param_weight: 0.0
  param_loss_type: "huber" # one of: mse, huber
  huber_delta: 0.02
  # Focus selection on param quality (previously activity F1 caused stage-1 local minimum)
  selection_metric: "val_active_param_rmse"
  train_backbone: true
  train_param_head: true
  train_activity_head: true
  balanced_sampler:
    enabled: true
    mode: "inverse_frequency" # one of: count_boost, inverse_frequency
    effects: ["lowpass", "bitcrush", "reverb", "highpass", "distortion", "playback_rate", "delay"]
    boost: 2.0
    base_weight: 1.0
  effect_loss_weights:
    lowpass: 1.0
    bitcrush: 1.5
    reverb: 1.0
    highpass: 1.0
    distortion: 1.0
    playback_rate: 1.5
    delay: 2.0
  batch_size: 256
  num_epochs: 150
  learning_rate: 0.0001
  val_split: 0.2
  # Single-stage joint training: removing stage-1 activity warmup which caused
  # the backbone to overfit to activity detection before param prediction was enabled,
  # trapping the model in a local minimum (best_epoch was always epoch 15 = stage-1 end).
  training_stages:
    - name: "joint_from_scratch"
      epochs: 150
      learning_rate: 0.0001
      lr_scheduler_type: "cosine"
      lr_min: 1.0e-6
      activity_loss_weight: 0.5
      activity_mismatch_weight: 2.0
      activity_mismatch_gamma: 2.0
      activity_loss_type: "asl"
      param_loss_weight: 1.0
      train_backbone: true
      train_param_head: true
      train_activity_head: true
      selection_metric: "val_active_param_rmse"
  post_train_analysis:
    enabled: true
    out_dir: null # null -> outputs/pipeline/controller/analysis
    val_split: null # null -> reuse controller.val_split
    split_seed: 42
    batch_size: 128
    num_renders: 5
    sample_rate: null # null -> reuse model.clap.sample_rate
    max_duration: null # null -> reuse model.clap.max_duration
    device: null # null -> reuse global device
    manifest_path: null # null -> data.augmented_audio_dir/manifest.jsonl
    hidden_dims: null # null -> reuse controller.hidden_dims
    dropout: null # null -> reuse controller.dropout

# === Phase B-AR: AR Hybrid Controller Training ===
ar_controller:
  condition_dim: 128
  hidden_dim: 256
  dropout: 0.1
  max_steps: 2
  num_epochs: 150
  batch_size: 256
  learning_rate: 0.0001
  weight_decay: 0.001
  val_split: 0.2
  seed: 42
  effect_loss_weight: 1.0
  param_loss_weight: 1.0
  huber_delta: 0.02
  lr_scheduler: "cosine"
  lr_min: 1.0e-6

# === Phase C: Visual Encoder ===
visual_encoder:
  # true: train/use Siamese visual encoder
  # false: skip Siamese and use direct CLIP similarity delta Sim(I')-Sim(I)
  enabled: false
  projection_dim: 768
  dropout: 0.1
  training:
    enabled: false
    batch_size: 32
    num_epochs: 40
    learning_rate: 0.0001
    val_split: 0.2
    seed: 42

# === Phase C: Inference ===
inference:
  top_k: 5

# === Output ===
output:
  dir: "outputs/pipeline"
