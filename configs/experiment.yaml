# Delta Correspondence Experiment Configuration
# Phase 0-2: Experimental validation and discovery

# Data configuration
data:
  root_dir: "data/experiment"
  image_subdir: "images"   # Landscape images organized by category
  audio_subdir: "audio"    # Electronic music clips
  max_images: 1000
  max_audio: 1000

  # Category filtering (optional)
  # If specified, only these categories will be processed
  # For images: folder names under images/
  # For audio: uses filename patterns or treats all as single category
  categories:
    image: ["ocean", "cliff", "volcano"]  # null = all categories, or list like ["ocean", "mountain_snowy", "desert_sand"]
    audio: null  # null = all audio files

  # Save augmented files (images/audio with effects applied)
  save_augmented: true  # Set to true to save augmented data
  augmented_dir: "outputs/augmented"  # Where to save augmented files

# Model configuration
model:
  # Primary embedders
  clip:
    name: "ViT-L-14"
    pretrained: "openai"
    embed_dim: 768

  clap:
    model_id: 1  # 630k+audioset non-fusion (music)
    enable_fusion: false
    embed_dim: 512
    sample_rate: 48000  # CLAP fixed at 48kHz (informational only)
    max_duration: 20.0  # seconds (truncate/pad for batch processing)

  # Cross-modal alignment
  alignment:
    method: "cca"
    n_components: 512
    fit_on_originals: true

  # Legacy (weights preserved, not used)
  imagebind:
    enabled: false
    embed_dim: 1024

# Phase 0 thresholds
thresholds:
  sensitivity:
    min_distance: 0.01  # Minimum delta norm to be considered sensitive

  linearity:
    min_cosine: 0.8  # Minimum mean pairwise cosine for consistency
    max_cv: 0.3  # Maximum CV of norms
    max_variance: 0.05  # Maximum cross-category variance

# Effects configuration
effects:
  intensities: ["low", "mid", "high"]

  image:
    types: ["brightness", "contrast", "saturation", "blur"]

  audio:
    types: ["lpf", "highshelf", "saturation", "reverb"]

# Effect mapping (hypothesis for retrieval evaluation)
effect_mapping:
  blur: "lpf"
  brightness: "highshelf"
  contrast: "saturation"
  saturation: "reverb"

# Statistical analysis
n_permutations: 10000

# Phase 3: Learning (The Decoder)
phase3:
  batch_size: 32
  num_epochs: 100
  learning_rate: 1e-4
  val_split: 0.2
  audio_duration: 10.0  # seconds
  max_audio_files: null  # null = use all files

# Output
output:
  dir: "outputs/experiment"
  save_plots: true
  plot_format: "png"

# Device
device: "mps"  # or "cuda" or "cpu"
